{
 "cells": [
 {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telecom Service Assurance AI Model (Transformer NN) for Latency Insights\n",
    "Author: Fatih E. NAR\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we showcase a machine learning model to create latency predictions for telecom networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "import onnx \n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.mixed_precision import Policy, set_global_policy\n",
    "\n",
    "# Check if CUDA (NVIDIA GPU) is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    device = \"/GPU:0\"\n",
    "    print(\"Using CUDA (NVIDIA GPU)\")\n",
    "else:\n",
    "    device = \"/CPU:0\"\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Example of setting a tensor to the device\n",
    "x = tf.random.uniform([3, 3])\n",
    "with tf.device(device):\n",
    "    x = tf.random.uniform([3, 3])\n",
    "print(x.device)\n",
    "\n",
    "# Load the generated data\n",
    "data = pd.read_csv('data/telecom_sevass_data.csv.xz', compression='xz', parse_dates=['timestamp'])\n",
    "\n",
    "# Inspect the data for problematic values\n",
    "print(\"Initial data inspection:\")\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "\n",
    "# Replace string representations of empty lists with NaN\n",
    "for col in ['latency', 'jitter', 'packet_loss', 'throughput', 'cpu_usage', 'memory_usage']:\n",
    "    data[col] = data[col].replace('[]', np.nan)\n",
    "\n",
    "# Ensure all relevant columns are numeric and replace non-numeric values with NaN\n",
    "for col in ['latency', 'jitter', 'packet_loss', 'throughput', 'cpu_usage', 'memory_usage']:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "# Impute missing values in numeric columns instead of dropping rows\n",
    "numeric_cols = ['latency', 'jitter', 'packet_loss', 'throughput', 'cpu_usage', 'memory_usage']\n",
    "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "\n",
    "# Create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i + seq_length].values)\n",
    "    return np.array(sequences)\n",
    "\n",
    "seq_length = 30  # Length of the sequences (e.g., 30 time steps)\n",
    "sequences = create_sequences(data[numeric_cols], seq_length)\n",
    "\n",
    "# Ensure sequences are numeric\n",
    "for i in range(sequences.shape[0]):\n",
    "    for j in range(sequences.shape[1]):\n",
    "        for k in range(sequences.shape[2]):\n",
    "            if isinstance(sequences[i, j, k], str):\n",
    "                sequences[i, j, k] = np.nan\n",
    "\n",
    "# Convert to float32\n",
    "X = sequences[:, :-1, :].astype(np.float32)  # Input sequences\n",
    "y = sequences[:, -1, :].astype(np.float32)   # Corresponding labels\n",
    "\n",
    "# Drop any remaining NaN values\n",
    "nan_mask = ~np.isnan(X).any(axis=(1, 2)) & ~np.isnan(y).any(axis=1)\n",
    "X = X[nan_mask]\n",
    "y = y[nan_mask]\n",
    "\n",
    "# Check shapes of the datasets\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'y shape: {y.shape}')\n",
    "print(f'X_train shape: {X[:int(0.8 * len(X))].shape}')\n",
    "print(f'X_val shape: {X[int(0.8 * len(X)):].shape}')\n",
    "print(f'y_train shape: {y[:int(0.8 * len(y))].shape}')\n",
    "print(f'y_val shape: {y[int(0.8 * len(y)):].shape}')\n",
    "\n",
    "# Ensure there's sufficient data for training\n",
    "if len(X) < 32:\n",
    "    raise ValueError('Not enough data to train the model. Increase the dataset size.')\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_val = X[:train_size], X[train_size:]\n",
    "y_train, y_val = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Transformer model\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(embed_dim),\n",
    "        ])\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "def build_transformer_model(input_shape, embed_dim, num_heads, ff_dim, num_layers):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Dense(embed_dim)(inputs)\n",
    "    for _ in range(num_layers):\n",
    "        x = TransformerBlock(embed_dim, num_heads, ff_dim)(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    outputs = Dense(input_shape[-1])(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (seq_length - 1, X.shape[-1])\n",
    "model = build_transformer_model(input_shape, embed_dim=64, num_heads=4, ff_dim=128, num_layers=2)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"mse\")\n",
    "model.summary()\n",
    "\n",
    "# Set the mixed precision policy\n",
    "policy = Policy('mixed_float16')\n",
    "set_global_policy(policy)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,  # Increase patience\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_val, y_val)\n",
    "print(f'Validation Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in Keras format\n",
    "model.save('data/service_assurance_transformer_model.keras')\n",
    "\n",
    "# Define a sample input for the model to create an input signature\n",
    "spec = (tf.TensorSpec((None, seq_length - 1, X.shape[-1]), tf.float32, name=\"input\"),)\n",
    "\n",
    "# Convert the Keras model to ONNX format\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13)\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "onnx_model_path = \"data/service_assurance_transformer_model.onnx\"\n",
    "onnx.save(onnx_model, onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Rescale the predictions and actual values back to the original scale\n",
    "y_pred_rescaled = scaler.inverse_transform(y_pred)\n",
    "y_val_rescaled = scaler.inverse_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_val_rescaled, y_pred_rescaled)\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions and actual values for a specific metric (e.g., latency)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(y_val_rescaled[:, 0], label='Actual Latency')\n",
    "plt.plot(y_pred_rescaled[:, 0], label='Predicted Latency')\n",
    "plt.title('Actual vs Predicted Latency')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Latency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
