{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telecom Revenue Assurance AI Model (El Classico with Ensemble)\n",
    "Author: Fatih E. NAR\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we showcase a machine learning model to detect fraudulent cases for telecom service use. We will use a synthetic dataset with features relevant to telco user activities, such as call duration, data usage, and SMS count. The goal is to accurately identify fraudulent events to help improve revenue assurance processes in the telco domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration\n",
    "We will start by loading and exploring the synthetic dataset to understand its structure and the distribution of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install dependencies\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "# Extract the .xz file\n",
    "with lzma.open('data/telecom_revass_data.csv.xz', 'rb') as f_in:\n",
    "    with open('data/telecom_revass_data.csv', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "# Load the synthetic telecom data\n",
    "data_path = \"data/telecom_revass_data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "data.info()\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Before training the model, we need to preprocess the data. This includes handling missing values, converting categorical variables to numeric, and splitting the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values in each column:\", missing_values)\n",
    "\n",
    "# Convert categorical variables to numeric\n",
    "data = pd.get_dummies(data, columns=['Plan_Type'], drop_first=True)\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = data.drop('Fraud', axis=1)\n",
    "y = data['Fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "We will use a Random Forest classifier to train the model. This involves fitting the model on the training data and then making predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114126e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the BalancedRandomForestClassifier with Fine-tuned hyperparameters \n",
    "model = BalancedRandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=200,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    max_depth=50,\n",
    "    bootstrap=True,\n",
    "    sampling_strategy='all',  # Set to 'all' to adopt future behavior\n",
    "    replacement=True  # Set to 'True' to silence the warning\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "We will evaluate the model's performance using metrics such as confusion matrix, classification report, and accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Make predictions on the test set with BalancedRandomForestClassifier\n",
    "y_pred = model.predict(X_test)\n",
    "# Evaluate the model\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"---------------\")\n",
    "print(\"BalancedRandomForestClassifier Results:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(acc_score)\n",
    "print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we built a machine learning model to detect fraudulent telecom events using a synthetic dataset. The Random Forest classifier showed good performance in identifying fraud. Further steps could involve hyperparameter tuning, feature engineering, and testing with real-world data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model\n",
    "Finally, we will save the trained model to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = \"models/brfc_model.pkl\"\n",
    "with open(model_path, 'wb') as model_file:\n",
    "    pickle.dump((model, X_train.columns.tolist()), model_file)\n",
    "print(f\"Revenue Assurance BalancedRandomForestClassifier Model Saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "920e2a1d55e66037258aa36f125af0b30dd28d4646a44908529bc7e2ced9cc6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
