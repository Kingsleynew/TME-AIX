{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telecom Revenue Assurance AI Model (El Classico with Ensemble)\n",
    "Author: Fatih E. NAR\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we showcase a machine learning model to detect fraudulent cases for telecom service use. We will use a synthetic dataset with features relevant to telco user activities, such as call duration, data usage, and SMS count. The goal is to accurately identify fraudulent events to help improve revenue assurance processes in the telco domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration\n",
    "We will start by loading and exploring the synthetic dataset to understand its structure and the distribution of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the synthetic telecom data\n",
    "data_path = \"data/telecom_revass_data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "data.info()\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Before training the model, we need to preprocess the data. This includes handling missing values, converting categorical variables to numeric, and splitting the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values in each column:\", missing_values)\n",
    "\n",
    "# Convert categorical variables to numeric\n",
    "data = pd.get_dummies(data, columns=['Plan_Type'], drop_first=True)\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = data.drop('Fraud', axis=1)\n",
    "y = data['Fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "We will use a Random Forest classifier to train the model. This involves fitting the model on the training data and then making predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# We are using Classifier (which handles non-linear relationships, robust to outliers, and can manage imbalanced datasets effectively) approach with Ensemble learning (Random Forest & Balanced Random Forest), which is a machine learning paradigm where multiple models (often referred to as \"weak learners\") are trained and combined to solve a particular problem. The idea is that by combining the predictions of multiple models, the ensemble can achieve better performance than any individual model alone. Ensemble learning techniques are widely used because they can significantly improve the accuracy, robustness, and generalizability of machine learning models.\n",
    "\n",
    "# Train a Random Forest classifier with class weights\n",
    "model_1 = RandomForestClassifier(n_estimators=100, random_state=42, class_weight={0: 1, 1: 10})\n",
    "model_1.fit(X_train, y_train)\n",
    "\n",
    "# Initialize and train the BalancedRandomForestClassifier with Fine-tuned hyperparameters \n",
    "model_2 = BalancedRandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=200,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    max_depth=50,\n",
    "    bootstrap=True,\n",
    "    sampling_strategy='all',  # Set to 'all' to adopt future behavior\n",
    "    replacement=True  # Set to 'True' to silence the warning\n",
    ")\n",
    "model_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "We will evaluate the model's performance using metrics such as confusion matrix, classification report, and accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Make predictions on the test set with RandomForestClassifier\n",
    "y_pred_1 = model_1.predict(X_test)\n",
    "# Evaluate the model\n",
    "print(\"---------------\")\n",
    "print(\"RandomForestClassifier Results:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_1))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_1))\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred_1))\n",
    "print(\"---------------\")\n",
    "\n",
    "# Make predictions on the test set with BalancedRandomForestClassifier\n",
    "y_pred_2 = model_2.predict(X_test)\n",
    "# Evaluate the model\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_2)\n",
    "class_report = classification_report(y_test, y_pred_2)\n",
    "acc_score = accuracy_score(y_test, y_pred_2)\n",
    "print(\"---------------\")\n",
    "print(\"BalancedRandomForestClassifier Results:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(acc_score)\n",
    "print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we built a machine learning model to detect fraudulent telecom events using a synthetic dataset. The Random Forest classifier showed good performance in identifying fraud. Further steps could involve hyperparameter tuning, feature engineering, and testing with real-world data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model\n",
    "Finally, we will save the trained model to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model1\n",
    "model1_path = \"models/telecom_revenueassurance_model1.pkl\"\n",
    "joblib.dump(model_1, model1_path)\n",
    "print(f\"Model-1: RandomForestClassifier saved to {model1_path}\")\n",
    "\n",
    "# Save the model2\n",
    "model2_path = \"models/telecom_revenueassurance_model2.pkl\"\n",
    "joblib.dump(model_2, model2_path)\n",
    "print(f\"Model-2: BalancedRandomForestClassifier saved to {model2_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "920e2a1d55e66037258aa36f125af0b30dd28d4646a44908529bc7e2ced9cc6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
